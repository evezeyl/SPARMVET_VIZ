# Dashboard App Layer:  `scr/app_shell` module
 The Shiny Layer (Visual Interaction) and User Interface (UI)


Workflow: Shiny (UI) eg. metadata upload → Signal → Polars (Filter) → Plotnine (Render) → Shiny (Display).



 #REVIEW : tree placement for code of the app ? cannot be only one script can it ?

## Architecture context

 **Decoupling Rendering:** 
 - Plotnine (first implementation of visualizations) creates static images (or SVGs). 
 These images are generated on the server, thus limiting calculations on the users's browser.
 This should provide the ability to visualize graphics for large datasets.


**Tidy Data Interface:** Plotnine _requires_ tidy data. 
 forces your 



### Role

Provides the Dashboard User Interface (UI) and handles Reactivity.

- We choose to use **Shiny Express** for prototyping. But changes are not excluded should this app evolve into a more complex app.

- It handles the sidebar, the file upload buttons, and the "Reactivity" (e.g., "When the user clicks E. coli, update the graph").

**Input:** Filtered, joined data from (bio_wranling : data_tier2) 

**Action:** Uses the **Graph Factory** to turn that data into Plotnine (evt. Plotly) objects.  

**Role:**
- A "remote control" for User Interaction for exploration (filters, selections, sliders and buttons) and "window for display"

### Placement
- app server 

### Architectural Benefit

Keeping this file "thin" (only UI and reactivity) makes it much easier to debug, faster to load, and easier to maintain.

Because: 
- Tidy data preparation BEFORE it touches the UI (shiny express app) makes it much faster to load (more data) and easier to debug. 

- [ ] TODO will require Docker to run into Galaxy (worse case scenario we go back to Shiny Core)
- [ ] TODO : persistence eg. user preferences -> account (could be in a YAML file)
#REVIEW -  where should we put eventual persistence of user preferences ? a YAML config file likely 

- Shiny Express (the language) and Standard Shiny (the deployment)


#### Remarks

- We favors usage of plotnine because it is an implementation of the grammar of graphics, which allows us to separate the "what" (data) from the "how" (visualization). Can also help producing publication ready figures. 
> We will start with this for prototyping 
BUT inconvenient is that it creates static plots. Data exploration expected by use of filters and selection of axes. Preview data datable 

- It is possible to further extends using plotly
- It is also possible to integrate python and R to create another plot factory for specialized plots. 
- It can be possible to refactor to standard shiny at a later stage, should the need arise. Keeping this layer thing should allow easier extension.

### Data Flow from dashboard

 **The "Instructions" Flow:**
 eg. When a user interacts with a Shiny slider, Shiny sends a small message (e.g., `{"species": "E. coli", "threshold": 5}`) to the server. The server runs the Polars filter, generates a _new_ Plotnine object, and sends the updated image back. #TODO this need to be on the graph in index.md


| User Action (Shiny UI) | Signal Sent to Server | Server Action (Polars/Python) | UI Result |
| --- | --- | --- | --- |
| **Uploads CSV** | File Stream | Validate headers + Join with data_tier1 | Show "Success" message |
| **Selects Species** | String: `"S. aureus"` | `df.filter(pl.col("country") == "Norway")` | Update all plots |
| **Filters by Date** | Range: `[2023, 2024]` | `df.filter(pl.col("year").is_between(2023, 2024))` | Re-render Plotly graph |


### Requirements 
- Running server (Docker container, Galaxy Interactive Tool)


## Implementation choices

- **Species switch**
    - [ ] ToDecide -> need to look at the data --> choices
        - Included in data (specified in Data contract for each species specified in YAML config file)
        - specified by user (dropdown in Dashboard)

. decided against WASM (Shinylive) BECAUSE we are leaning towards a server-side model for scalability. The architecture actually gets _more_ robust

## DEVELOPMENT 

- [ ] Python class for the `MetadataManager` :  handles the Polars join and validation logic.
First piece #REVIEW - of the "Server-side" engine.

- [ ]  **"MetadaData Health Report"** -> must be given eg. if fails to upload metadata given by the user (to help find error). Eg could not find matching id, format osv
